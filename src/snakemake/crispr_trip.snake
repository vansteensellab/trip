import getpass
import datetime
import inspect
import os
import re

filename = inspect.getframeinfo(inspect.currentframe()).filename
path = os.path.dirname(os.path.abspath(filename))

# user = getpass.getuser()
# date = datetime.datetime.now()
# date = '%i%0.2i%0.2i' % (date.year, date.month, date.day)

def parse_meta(meta_file):
    with open(meta_file) as f:
        header = f.readline().strip().split('\t')
        id_i = header.index('ID')
        type_i = header.index('PCR_type')
        file_i = header.index('file')
        for line in f.readlines():
            line_split = line.strip().split('\t')
            yield(line_split[type_i], line_split[id_i], line_split[file_i])

if 'META_INFO' in config:
    if 'input_file' not in config:
        config['input_file'] = {}
    for type, id, file in parse_meta(config['META_INFO']):
        if type not in config['input_file']:
            config['input_file'][type] = {}
        config['input_file'][type][id] = file.split(',')

def get_all(config):
    for type in config['input_file'].keys():
        for file in get_input(config, type):
            yield(file)
        if 'useSpike' in config and config['useSpike']:
            for file in get_input(config, type, True):
                yield(file)

def get_input(config, type, isSpike=False):
    if isSpike:
        pattern_dict = {
            'indelPCR': ['{outdir}/spike/indelPCR.{name}.raw.count'],
            'bcPCR': ['{outdir}/spike/bcPCR.{name}.raw.count'],
            'iPCR': ['{outdir}/spike/mapping.{name}.raw.count']
        }
    else:
        pattern_dict = {
            'indelPCR': ['{outdir}/indelPCR_counts/{name}.count.table'],
            'bcPCR': ['{outdir}/counts/bcPCR.{name}.starcode.count'],
            'iPCR': ['{outdir}/table/mapping.{name}.1.table',
                     '{outdir}/table/mapping.{name}.2.table']
        }
    type_dict = config['input_file'][type]
    for id in type_dict:
        for pattern in pattern_dict[type]:
            yield(pattern.format(outdir=config['outdir'],
                                 name=id))

rule all:
    input:
        get_all(config)

if 'bcPCR' in config['input_file']:
    rule bc_only:
        input:
            get_input(config, 'bcPCR')
if 'indelPCR' in config['input_file']:
    rule mutation_only:
        input:
            get_input(config, 'indelPCR')
if 'iPCR' in config['input_file']:
    rule mapping_only:
        input:
            get_input(config, 'iPCR')

rule specific:
    input:
        expand('{outdir}/specificIndel/{name}.count.table',
               outdir=config['outdir'], name=config['input_file']['indelPCR'])


rule specific_indel:
    input:
        '{outdir}/indelPCR_counts/{name}.tsv',
        '{outdir}/indel_align.tsv'
    output:
        '{outdir}/specificIndel/{name}.count.table'
    run:
        import pandas
        count = pandas.read_table(input[0], index_col=False,
                                  names=['count', 'barcode', 'call', 'indel', 'seq'])
        indel = pandas.read_csv(input[1])
        for name in ['count', 'call']:
            indel = indel.drop(name, 1)
        out = pandas.merge(count, indel, on='seq', how='left')
        out.to_csv(output[0], sep='\t', index=False, float_format="%i",
                   na_rep="NA")



rule combine_mutation:
    input:
        '{outdir}/indelPCR_counts/{name}.tsv'
    output:
        '{outdir}/indelPCR_counts/{name}.count.table'
    run:
        import pandas
        count = pandas.read_table(input[0], names=('count','barcode',
                                                   'call', 'indel', 'seq'))
        count_sum = count.groupby(['barcode', 'call', 'indel'])['count'].sum()
        count_sum.to_csv(output[0], sep='\t', index=True, header=True,
                         float_format="%i")


rule count_mutation:
    input:
        '{outdir}/indelPCR/{name}.genuine.table'
    output:
        '{outdir}/indelPCR_counts/{name}.tsv'
    threads:
        5
    shell:
        "sort --parallel={threads} {input} | uniq -c | "
        "awk -vOFS='\t' '{{print $1, $2, $3, $4, $5}}'> {output}"


rule align_indel:
    input:
        expand('{{outdir}}/specificIndel/{name}.txt',
               name=config['input_file']['indelPCR'].keys())
    output:
        '{outdir}/indel_align.tsv'
    params:
        min_count=1000,
        breaksite=config['breaksite'],
        sequence=config['sequence']
    script:
        'scripts/align_indelPCR.R'

rule uniq_seq:
    input:
        '{outdir}/indelPCR/{name}.genuine.table'
    output:
        '{outdir}/specificIndel/{name}.txt'
    shell:
        "awk '{{if ($2==\"ins\"||$2==\"del\"){{print $4, $2}}}}' {input} | "
        "sort -k1 | uniq -c | sort -k1rn > {output}"

rule genuine_barcodes:
    input:
        '{outdir}/{type}/{name}.raw.table',
        '{outdir}/counts/{type}.{name}.starcode.count'
    output:
        '{outdir}/{type}/{name}.not_genuine.table',
        '{outdir}/{type}/{name}.genuine.table'
    script:
        'scripts/genuine_barcodes.py'


rule call_mutation:
    input:
        '{outdir}/parsed/indelPCR.{name}.barcode.txt.gz'
    output:
        '{outdir}/indelPCR/{name}.raw.table'
    params:
        target = config['crispr_target'],
        spacer_list = config['spacer_list'],
        gap_list = config['gap_list']
    script:
        'scripts/call_mutation.py'


rule parse_sam:
    input:
        bam='{outdir}/aligned/{name}.{num}.bam',
        count='{outdir}/counts/mapping.{name}.starcode.count',
    output:
        bed='{outdir}/bed/mapping.{name}.{num}.bed',
        table='{outdir}/table/mapping.{name}.{num}.table',
        stats='{outdir}/stats/mapping.{name}.{num}.parse_stat.table',
        length='{outdir}/stats/mapping.{name}.{num}.length.table',
        remap_fq='{outdir}/aligned/mapping.{name}.{num}.remap.fastq.gz',
        remap='{outdir}/aligned/mapping.{name}.{num}.remap.bam'
    wildcard_constraints:
        num="\d+"
    params:
        bowtie_index = config['bowtie']['index'],
        options=config['bowtie']['options'],
        max_dist = lambda wildcards: config['max_dist'][wildcards.num],
        num='{num}'
    threads: 10
    script:
        'scripts/parse_sam.py'


if 'iPCR' in config['input_file']:
    rule align:
        input:
            '{outdir}/parsed/mapping.{name}.{num}.fastq.gz'
        output:
            '{outdir}/aligned/{name}.{num}.bam'
        params:
            bowtie_index=config['bowtie']['index'],
            options=config['bowtie']['options'],
            num='{num}'
        wildcard_constraints:
            num="\d+"
        threads: 10
        log:
            '{outdir}/mapping.align.{name}.{num}.log'
        run:
            options = params.options[params.num]
            shell("{path}/scripts/align.sh {input} {log} {threads} "
                  "{options} {params.bowtie_index} {output}")



rule starcode:
    input:
        '{outdir}/counts/{read_type}.{name}.raw.count'
    output:
        gen='{outdir}/counts/{read_type}.{name}.starcode.count',
        mut='{outdir}/counts/{read_type}.{name}.genuine.cut',
        count='{outdir}/counts/{read_type}.{name}.count.cut'
    params:
        lev_dist = config['lev_dist'],
        use_other = False,
        read_type = '{read_type}',
        count= lambda wildcards: config['min_count'][wildcards.read_type]
    threads:
        3
    script:
        'scripts/starcode.py'


def get_count_input(wildcards):
    if wildcards.count_type == 'counts':
        return('{outdir}/parsed/{read_type}.{name}.barcode.txt.gz'.format(
                   outdir=wildcards.outdir, read_type=wildcards.read_type,
                   name=wildcards.name))
    elif wildcards.count_type == 'spike':
        return('{outdir}/spike_parse/{read_type}.{name}.barcode.txt.gz'.format(
                   outdir=wildcards.outdir, read_type=wildcards.read_type,
                   name=wildcards.name))



rule count_barcode:
    input:
        lambda wildcards: get_count_input(wildcards)
    output:
        '{outdir}/{count_type}/{read_type}.{name}.raw.count'
    params:
        path=path
    shell:
        "{params.path}/scripts/count_barcode.sh {input} > {output}"


def get_input_file(config, wildcards):
    if 'indir' in config:
        indir = config['indir']
        if indir.endswith('/'):
            pattern = '%s%s'
        else:
            pattern = '%s/%s'
        for file in config['input_file'][wildcards.type][wildcards.name]:
            yield(pattern % (config['indir'], file))
    else:
        for file in config['input_file'][wildcards.type][wildcards.name]:
            yield(file)

if 'useSpike' in config and config['useSpike']:
    rule parse_spike:
        input:
            lambda wildcards: get_input_file(config, wildcards)
        output:
            '{outdir}/spike_parse/{type}.{name}.barcode.txt.gz',
            '{outdir}/spike_parse/{type}.{name}.statistics.txt',
            structure = '{outdir}/spike_parse/{type}.{name}.structure.txt'
        log:
            '{outdir}/stats/spike.{type}.{name}_parser.log'
        params:
            structure= config['spike_structure'],
            outdir = '{outdir}/spike_parse/'
        run:
            with open(output.structure, 'w') as f:
                f.write(params.structure[wildcards.type])
            shell('~t.v.schaik/mydata/modules/read-parsing/read_parser.py -a -r -s -l {log} '
                  '-b {wildcards.type}.{wildcards.name} {input} {output.structure} '
                  '{params.outdir}')


rule parse_mutation:
    input:
        lambda wildcards: get_input_file(config, wildcards)
    output:
        '{outdir}/parsed/{type}.{name}.barcode.txt.gz',
        '{outdir}/parsed/{type}.{name}.statistics.txt',
        structure = '{outdir}/parsed/{type}.{name}.structure.txt'
    log:
        '{outdir}/stats/{type}.{name}_parser.log'
    params:
        structure= config['structure'],
        outdir = '{outdir}/parsed/'
    run:
        with open(output.structure, 'w') as f:
            f.write(params.structure[wildcards.type])
        shell('~t.v.schaik/mydata/modules/read-parsing/read_parser.py -a -r -s -l {log} '
              '-b {wildcards.type}.{wildcards.name} {input} {output.structure} '
              '{params.outdir}')

if 'iPCR' in config['input_file']:
    ruleorder: parse_mapping > parse_mutation

    rule parse_mapping:
        input:
            lambda wildcards: list(get_input_file(config, wildcards))[0]
        output:
            '{outdir}/parsed/mapping.{name}.barcode.txt.gz',
            '{outdir}/parsed/mapping.{name}.1.fastq.gz',
            '{outdir}/parsed/mapping.{name}.2.fastq.gz',
            '{outdir}/parsed/mapping.{name}.statistics.txt',
            structure = '{outdir}/parsed/mapping.{name}.structure.txt'
        log:
            '{outdir}/parsed/mapping.{name}_parser.log'
        params:
            structure= config['structure']['iPCR'],
            outdir = '{outdir}/parsed/',
            name= '{name}'
        run:
            with open(output.structure, 'w') as f:
                f.write(params.structure)
            shell('~t.v.schaik/mydata/modules/read-parsing/read_parser.py -r -a -l {log} -p {input[1]} '
                  '-b mapping.{wildcards.name} {input[0]} {output.structure} {params.outdir}')
